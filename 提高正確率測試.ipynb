{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一個model:上課範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 4)                 3140      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,180\n",
      "Trainable params: 3,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(4, input_dim = 28*28))\n",
    "model_1.add(Activation('softplus'))\n",
    "model_1.add(Dense(2))\n",
    "model_1.add(Activation('softplus'))\n",
    "model_1.add(Dense(10))\n",
    "model_1.add(Activation('softmax'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss = \"mse\",optimizer=SGD(lr = 0.087),metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0865 - acc: 0.1030\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0807 - acc: 0.2579\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0796 - acc: 0.2847\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0790 - acc: 0.2908\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0782 - acc: 0.2954\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0776 - acc: 0.2967\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0770 - acc: 0.2980\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0765 - acc: 0.2983\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0760 - acc: 0.2989\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0756 - acc: 0.2990\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0751 - acc: 0.2984\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0747 - acc: 0.2977\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0744 - acc: 0.2982\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.0742 - acc: 0.2983\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.0739 - acc: 0.3025\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.0736 - acc: 0.3033\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0735 - acc: 0.3030\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.0733 - acc: 0.3034\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0731 - acc: 0.3042\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0730 - acc: 0.3040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb375cb400>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train,y_train, batch_size=100,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正確率低，約30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二個model:調整learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,070\n",
      "Trainable params: 8,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1307 - acc: 0.3348\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0879 - acc: 0.5548\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0833 - acc: 0.5802\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0808 - acc: 0.5932\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0783 - acc: 0.6061\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0778 - acc: 0.6091\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0774 - acc: 0.6116\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0767 - acc: 0.6150\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0762 - acc: 0.6176\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0761 - acc: 0.6181\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0762 - acc: 0.6181\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0752 - acc: 0.6227\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0771 - acc: 0.6132\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0751 - acc: 0.6236\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0752 - acc: 0.6234\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0736 - acc: 0.6312\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0740 - acc: 0.6294\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0745 - acc: 0.6269\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0746 - acc: 0.6260\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0744 - acc: 0.6267\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(10, input_dim = 28*28))\n",
    "model_2.add(Activation('softplus'))\n",
    "model_2.add(Dense(10))\n",
    "model_2.add(Activation('softplus'))\n",
    "model_2.add(Dense(10))\n",
    "model_2.add(Activation('softmax'))\n",
    "model_2.summary()\n",
    "model_2.compile(loss = \"mse\",optimizer=SGD(lr = 0.1),metrics=[\"accuracy\"]) \n",
    "model_2 = model_2.fit(x_train,y_train,batch_size=100,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調高learning rate，正確率上升：大約從30%上升到63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三個model:調整神經元數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1098 - acc: 0.1862\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0867 - acc: 0.3778\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0844 - acc: 0.4962\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0821 - acc: 0.5579\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.5845\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0781 - acc: 0.6051\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0763 - acc: 0.6218\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0743 - acc: 0.6392\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0725 - acc: 0.6500\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0708 - acc: 0.6614\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0692 - acc: 0.6779\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0676 - acc: 0.6907\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0661 - acc: 0.7021\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0646 - acc: 0.7180\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0630 - acc: 0.7255\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0615 - acc: 0.7344\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0600 - acc: 0.7420\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0586 - acc: 0.7500\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0571 - acc: 0.7569\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0557 - acc: 0.7640\n"
     ]
    }
   ],
   "source": [
    "model_3= Sequential()\n",
    "model_3.add(Dense(20, input_dim = 28*28))\n",
    "model_3.add(Activation('hard_sigmoid'))\n",
    "model_3.add(Dense(20))\n",
    "model_3.add(Activation('hard_sigmoid'))\n",
    "model_3.add(Dense(10))\n",
    "model_3.add(Activation('hard_sigmoid'))\n",
    "model_3.summary()\n",
    "model_3.compile(loss = \"mse\",optimizer=SGD(lr = 0.087),metrics=[\"accuracy\"]) #告知loss function\n",
    "model_3 =model_3.fit(x_train,y_train,batch_size=100,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將第一二層的神經元都增加到20個，正確率大幅提升到約76%\n",
    "上升程度比調高learning rate高一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四個模型：增加層數(三層)\n",
    "因為增加神經元有效提高正確率，所以各層維持較多的神經元數量\n",
    "因為提高learning rate有效提高正確率，所以維持較高的learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,750\n",
      "Trainable params: 16,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1326 - acc: 0.3309\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.1004 - acc: 0.4930\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0928 - acc: 0.5320\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0914 - acc: 0.5393\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.5996\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0757 - acc: 0.6193\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0736 - acc: 0.6296\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0714 - acc: 0.6405\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0716 - acc: 0.6402\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0710 - acc: 0.6431\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0713 - acc: 0.6409\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0705 - acc: 0.6446\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0669 - acc: 0.6604\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0556 - acc: 0.7173\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0531 - acc: 0.7286\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0493 - acc: 0.7369\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0373 - acc: 0.7742\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0274 - acc: 0.8410\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0243 - acc: 0.8702\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0225 - acc: 0.8834\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(20, input_dim = 28*28))\n",
    "model_4.add(Activation('softplus'))\n",
    "model_4.add(Dense(20))\n",
    "model_4.add(Activation('softplus'))\n",
    "model_4.add(Dense(20))\n",
    "model_4.add(Activation('softplus'))\n",
    "model_4.add(Dense(10))\n",
    "model_4.add(Activation('softmax'))\n",
    "model_4.summary()\n",
    "model_4.compile(loss = \"mse\",optimizer=SGD(lr = 0.1),metrics=[\"accuracy\"]) \n",
    "model_4 =model_4.fit(x_train,y_train,batch_size=100,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正確率提高至大約88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五個模型：調整batch_size & epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,750\n",
      "Trainable params: 16,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0512 - acc: 0.6652\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0273 - acc: 0.8312\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0215 - acc: 0.8655\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0190 - acc: 0.8832\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0175 - acc: 0.8932\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0161 - acc: 0.9013\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0151 - acc: 0.9078\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0144 - acc: 0.9123\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0141 - acc: 0.9142\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0134 - acc: 0.9185\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0127 - acc: 0.9228\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0121 - acc: 0.9257\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0118 - acc: 0.9269\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0114 - acc: 0.9304\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0110 - acc: 0.9334\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0107 - acc: 0.9349\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0104 - acc: 0.9368\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0102 - acc: 0.9383\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0101 - acc: 0.9384\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0099 - acc: 0.9400\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0096 - acc: 0.9416\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0094 - acc: 0.9425\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0092 - acc: 0.9439\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0091 - acc: 0.9445\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0090 - acc: 0.9445\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0089 - acc: 0.9457\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0087 - acc: 0.9471\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0085 - acc: 0.9479\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0084 - acc: 0.9483\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0083 - acc: 0.9490\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0081 - acc: 0.9503\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0080 - acc: 0.9506\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0078 - acc: 0.9520\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0078 - acc: 0.9526\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0078 - acc: 0.9525\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0077 - acc: 0.9534\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0075 - acc: 0.9541\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0075 - acc: 0.9549\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0074 - acc: 0.9548\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0073 - acc: 0.9551\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0072 - acc: 0.9562\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0071 - acc: 0.9564\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0071 - acc: 0.9574\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0070 - acc: 0.9571\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0069 - acc: 0.9576\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0069 - acc: 0.9582\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0068 - acc: 0.9585\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0067 - acc: 0.9589\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0068 - acc: 0.9589\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0067 - acc: 0.9593\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0066 - acc: 0.9601\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0064 - acc: 0.9614\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0065 - acc: 0.9608\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0065 - acc: 0.9606\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0064 - acc: 0.9612\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0063 - acc: 0.9615\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0062 - acc: 0.9625\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0062 - acc: 0.9625\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0061 - acc: 0.9632\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0060 - acc: 0.9638\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0061 - acc: 0.9632\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0061 - acc: 0.9632\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0059 - acc: 0.9643\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0059 - acc: 0.9645\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0059 - acc: 0.9641\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0058 - acc: 0.9650\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0058 - acc: 0.9650\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0058 - acc: 0.9647\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0058 - acc: 0.9651\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0057 - acc: 0.9653\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0057 - acc: 0.9655\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0057 - acc: 0.9656\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0055 - acc: 0.9667\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0056 - acc: 0.9666\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0056 - acc: 0.9662\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0055 - acc: 0.9665\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0054 - acc: 0.9674\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0054 - acc: 0.9676\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0055 - acc: 0.9668\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0054 - acc: 0.9672\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0054 - acc: 0.9672\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0053 - acc: 0.9680\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0053 - acc: 0.9684\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0053 - acc: 0.9678\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0051 - acc: 0.9692\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0053 - acc: 0.9677\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0051 - acc: 0.9692\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0051 - acc: 0.9697\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0051 - acc: 0.9695\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0051 - acc: 0.9695\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0051 - acc: 0.9697\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0052 - acc: 0.9690\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0051 - acc: 0.9694\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0050 - acc: 0.9700\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0051 - acc: 0.9697\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0050 - acc: 0.9701\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0050 - acc: 0.9699\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0049 - acc: 0.9706\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0051 - acc: 0.9690\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Dense(20, input_dim = 28*28))\n",
    "model_5.add(Activation('softplus'))\n",
    "model_5.add(Dense(20))\n",
    "model_5.add(Activation('softplus'))\n",
    "model_5.add(Dense(20))\n",
    "model_5.add(Activation('softplus'))\n",
    "model_5.add(Dense(10))\n",
    "model_5.add(Activation('softmax'))\n",
    "model_5.summary()\n",
    "model_5.compile(loss = \"mse\",optimizer=SGD(lr = 0.1),metrics=[\"accuracy\"]) \n",
    "model_5 =model_5.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調高epochs，正確率提升到約97%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "認為可能可以提高正確率的方法：\n",
    "\n",
    "1.調高learning rate\n",
    "\n",
    "2.增加每層神經元數量\n",
    "\n",
    "3.增加層數\n",
    "\n",
    "4.調高epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
